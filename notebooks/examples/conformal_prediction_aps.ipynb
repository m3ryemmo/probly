{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ada5e7c",
   "metadata": {},
   "source": [
    "# Adaptive Prediction Sets (APS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f3ac81",
   "metadata": {},
   "source": [
    "### The Problem of Uncertainty in Machine Learning Predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726859c4",
   "metadata": {},
   "source": [
    "Traditional ML models do not provide information about **uncertainty or reliabilty**. But that is **crucial** in criitical applications, that are in need of **guaranteed coverage**.\n",
    "\n",
    "An example for such application would be an autuonomous driving application. It is not enough to predcit \"It is a pedestrian\", the application has **to be confident** about something on the road being \"a pederian, cyclist or traffic sign\", to prevent serious concequences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b48e538",
   "metadata": {},
   "source": [
    "### Core Idea: Conformal Prediction\n",
    "\n",
    "While traditional ML models only provide point predictions, APS provide prediction sets. \n",
    "\n",
    "Traditional: Model predicts \"class 3\"\n",
    "\n",
    "APS: Model predicts \"{2, 3, 5}\" with 90% confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e287dbbe",
   "metadata": {},
   "source": [
    "### Marginal Coverage\n",
    "\n",
    "Marginal coverage provides a statistical guarantee.\n",
    "\n",
    "$$\\mathbb{P}[Y_{n+1} \\in \\hat{C}_{n,\\alpha}(X_{n+1})] \\geq 1-\\alpha$$\n",
    "\n",
    "Where: \n",
    "- $\\mathbb{P}[\\cdot]$: Probability operator\n",
    "- $Y_{n+1}$: Unknown true label we want to predict\n",
    "- $\\hat{\\mathcal{C}}_{n,\\alpha}(\\cdot)$: prediction set function that maps features\n",
    "- $X_{n+1}$: Observed features of test point\n",
    "- $1-\\alpha$: Target probability of coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6cef74",
   "metadata": {},
   "source": [
    "Let's look at a simple coverage test, where $\\alpha=0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c638ecac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test images: 10\n",
      "Target coverage: 0.9 (90%)\n",
      "Actual coverage: 0.9 (90.0%)\n",
      "Coverage >= Target coverage: True\n",
      "Calculation: 9 / 10 = 0.9\n"
     ]
    }
   ],
   "source": [
    "test_images = 10\n",
    "alpha = 0.1\n",
    "target_coverage = 1 - alpha\n",
    "\n",
    "results = [1, 1, 1, 1, 1, 1, 1, 0, 1, 1]  # 9 out of 10 correct\n",
    "\n",
    "coverage = sum(results) / len(results)\n",
    "\n",
    "print(f\"Number of test images: {test_images}\")\n",
    "print(f\"Target coverage: {target_coverage} (90%)\")\n",
    "print(f\"Actual coverage: {coverage} ({coverage * 100}%)\")\n",
    "print(f\"Coverage >= Target coverage: {coverage >= target_coverage}\")\n",
    "print(f\"Calculation: {sum(results)} / {len(results)} = {coverage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1931adb0",
   "metadata": {},
   "source": [
    "### The APS Algorithm\n",
    "\n",
    "Provides the Conformity Score:\n",
    "$$ E(x,y,u;\\hat{\\pi}) = \\min\\{\\tau \\in [0,1] : y \\in \\mathcal{S}(x,u;\\hat{\\pi},\\tau)\\} $$\n",
    "\n",
    "The conformity score measures the **minimum probability threshold** at which the true label would be included in the prediction set, quantifying how **\"surprised\"** the model is by the correct answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69684190",
   "metadata": {},
   "source": [
    "Following: A Simple APS Conformity Score implemented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "219213e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def aps_conformity_score(self, probabilities: np.ndarray, true_labels: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    E(x,y,u;π̂) = min{τ ∈ [0,1] : y ∈ S(x,u;π̂,τ)}\n",
    "    \n",
    "    Finds the minimum threshold τ at which the true class \n",
    "    is included in the prediction set.\n",
    "    \"\"\"\n",
    "    conformity_scores = []\n",
    "\n",
    "    for true_label, probs in zip(true_labels, probabilities):\n",
    "        #descending\n",
    "        sorted_indices = np.argsort(probs)[::-1]\n",
    "        sorted_probs = probs[sorted_indices]\n",
    "\n",
    "        cumulative_probs = np.cumsum(sorted_probs)\n",
    "\n",
    "        true_class_pos = np.where(sorted_indices == true_label)[0][0]\n",
    "\n",
    "        #score is cumulative prob up to the true class\n",
    "        aps_score = cumulative_probs[true_class_pos]\n",
    "        conformity_scores.append(aps_score)\n",
    "\n",
    "    return np.array(conformity_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b0e5d5",
   "metadata": {},
   "source": [
    "Where inputs are probabilitites(model's predicted probabilities), true_labels.\n",
    "\n",
    "For each sample, sort classes by probability and find the **cumulative probability at whih the true class is included**.\n",
    "\n",
    "Low conformity score means the model is \"suprised\" by the true label.\n",
    "\n",
    "Mathemathical Interpretation: The minimum probability threshold τ where the true class y would be included in the prediction set S(x,τ)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094cb10d",
   "metadata": {},
   "source": [
    "### APS implemented on Iris Dataset\n",
    "\n",
    "1. Whats is the Iris Dataset? \n",
    "The Iris Dataset is a classical benchmark dataset, whih contains 150 samples. It is an ideal dataset to test and teach such algoriths through examples.\n",
    "\n",
    "Heres an implementation of Iris and APS implemented:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b794be9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (875457832.py, line 33)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 33\u001b[1;36m\u001b[0m\n\u001b[1;33m    def train_model(self, X_train_: np.ndarray, y_train: np.ndarray):\u001b[0m\n\u001b[1;37m                                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from typing import Tuple, List, Dict, Any\n",
    "import pandas as pd\n",
    "\n",
    "class APSIrisImplementation:\n",
    "    \"\"\"Complete APS Implementation\"\"\"\n",
    "\n",
    "    def __init__(self, significance_level: float = 0.1):\n",
    "        self.significance_level = significance_level\n",
    "        self.model = None\n",
    "        self.quantile = None\n",
    "        self.calibration_scores = None\n",
    "\n",
    "        def load_prepare_data(self) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "            \"\"\"Load and split the Iris dataset\"\"\"\n",
    "            iris = load_iris()\n",
    "            X, y = iris.data, iris.target\n",
    "            feature_names = iris.feature_names\n",
    "            target_names = iris.target_names\n",
    "\n",
    "            #split inot train, calib, and test set\n",
    "            X_temp, X_test, y_temp, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n",
    "            X_train, X_calib, y_train, y_calib = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp)\n",
    "\n",
    "            return X_train, X_calib, X_test, y_train, y_calib, y_test, feature_names, target_names\n",
    "        \n",
    "        def train_model(self, X_train: np.ndarray, y_train: np.ndarray):\n",
    "            \"\"\"Train base classifier\"\"\"\n",
    "            self.model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            self.model.fit(X_train, y_train)\n",
    "            return self.model\n",
    "        \n",
    "        aps_conformity_score()\n",
    "\n",
    "        def calculate_prediction_sets(self, probabilities: np.ndarray, tau )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "probly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
