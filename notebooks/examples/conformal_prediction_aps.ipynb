{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ada5e7c",
   "metadata": {},
   "source": [
    "# Adaptive Prediction Sets (APS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f3ac81",
   "metadata": {},
   "source": [
    "### The Problem of Uncertainty in Machine Learning Predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726859c4",
   "metadata": {},
   "source": [
    "Traditional ML models do not provide information about **uncertainty or reliabilty**. But that is **crucial** in criitical applications, that are in need of **guaranteed coverage**.\n",
    "\n",
    "An example for such application would be an autuonomous driving application. It is not enough to predcit \"It is a pedestrian\", the application has **to be confident** about something on the road being \"a pederian, cyclist or traffic sign\", to prevent serious concequences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b48e538",
   "metadata": {},
   "source": [
    "### Core Idea: Conformal Prediction\n",
    "\n",
    "While traditional ML models only provide point predictions, APS provide prediction sets. \n",
    "\n",
    "Traditional: Model predicts \"class 3\"\n",
    "\n",
    "APS: Model predicts \"{2, 3, 5}\" with 90% confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e287dbbe",
   "metadata": {},
   "source": [
    "### Marginal Coverage\n",
    "\n",
    "Marginal coverage provides a statistical guarantee.\n",
    "\n",
    "$$\\mathbb{P}[Y_{n+1} \\in \\hat{C}_{n,\\alpha}(X_{n+1})] \\geq 1-\\alpha$$\n",
    "\n",
    "Where: \n",
    "- $\\mathbb{P}[\\cdot]$: Probability operator\n",
    "- $Y_{n+1}$: Unknown true label we want to predict\n",
    "- $\\hat{\\mathcal{C}}_{n,\\alpha}(\\cdot)$: prediction set function that maps features\n",
    "- $X_{n+1}$: Observed features of test point\n",
    "- $1-\\alpha$: Target probability of coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6cef74",
   "metadata": {},
   "source": [
    "Let's look at a simple coverage test, where $\\alpha=0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c638ecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = 10\n",
    "alpha = 0.1\n",
    "target_coverage = 1 - alpha\n",
    "\n",
    "results = [1, 1, 1, 1, 1, 1, 1, 0, 1, 1]  # 9 out of 10 correct\n",
    "\n",
    "coverage = sum(results) / len(results)\n",
    "\n",
    "print(f\"Number of test images: {test_images}\")\n",
    "print(f\"Target coverage: {target_coverage} (90%)\")\n",
    "print(f\"Actual coverage: {coverage} ({coverage * 100}%)\")\n",
    "print(f\"Coverage >= Target coverage: {coverage >= target_coverage}\")\n",
    "print(f\"Calculation: {sum(results)} / {len(results)} = {coverage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1931adb0",
   "metadata": {},
   "source": [
    "### The APS Algorithm\n",
    "\n",
    "Provides the Conformity Score:\n",
    "$$ E(x,y,u;\\hat{\\pi}) = \\min\\{\\tau \\in [0,1] : y \\in \\mathcal{S}(x,u;\\hat{\\pi},\\tau)\\} $$\n",
    "\n",
    "The conformity score measures the **minimum probability threshold** at which the true label would be included in the prediction set, quantifying how **\"surprised\"** the model is by the correct answer.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
